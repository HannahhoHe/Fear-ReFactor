{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "import pandas as pd\n",
    "sys.path.append('/home/ubuntu/Mask_RCNN/samples/coco') \n",
    "import coco\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get total number of images in each dataset (training vs. validation: n, p)\n",
    "\n",
    "class ClownDataset(Dataset):\n",
    "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
    "\t\tself.add_class(\"dataset\", 1, \"clown\")\n",
    "\t\tself.add_class(\"dataset\", 2, \"others\")   \n",
    "\t\timages_dir = dataset_dir + '/images/'\n",
    "\t\tannotations_dir = dataset_dir + '/annots/'\n",
    "\t\tfor filename in listdir(images_dir):\n",
    "\t\t\timage_id = filename[:-4]\n",
    "\t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path, class_ids=[0,1,2])\n",
    "\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\ttree = ElementTree.parse(filename)\n",
    "\t\troot = tree.getroot()\n",
    "\t\tboxes = list()\n",
    "\t\tfor box in root.findall('.//bndbox'):\n",
    "\t\t\txmin = int(box.find('xmin').text)\n",
    "\t\t\tymin = int(box.find('ymin').text)\n",
    "\t\t\txmax = int(box.find('xmax').text)\n",
    "\t\t\tymax = int(box.find('ymax').text)\n",
    "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
    "\t\t\tboxes.append(coors)\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    "\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\tpath = info['annotation']\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tif i == 0:                                    \n",
    "\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1                   \n",
    "\t\t\t\tclass_ids.append(self.class_names.index('clown'))      \n",
    "\t\t\telse:                                         \n",
    "\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 2                 \n",
    "\t\t\t\tclass_ids.append(self.class_names.index('others'))    \n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')                \n",
    "\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']\n",
    "\n",
    "class PredictionConfig(Config):\n",
    "\tNAME = \"Clown_cfg\"\n",
    "\tNUM_CLASSES = 1 + 2\n",
    "\tGPU_COUNT = 1\n",
    "\tIMAGES_PER_GPU = 1\n",
    "\n",
    "\n",
    "def evaluate_model(dataset, model, cfg):\n",
    "    APs = list();\n",
    "    F1_scores = list();\n",
    "    PRECISION = list();\n",
    "    RECALL = list();\n",
    "    OVERLAPS = list();\n",
    "    class_id = list(); \n",
    "    \n",
    "    for image_id in dataset.image_ids:\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
    "        scaled_image = mold_image(image, cfg)\n",
    "        sample = expand_dims(scaled_image, 0)\n",
    "        yhat = model.detect(sample, verbose=0)\n",
    "        r = yhat[0]\n",
    "        AP, precision, recalls, overlaps = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'],\n",
    "                                iou_threshold=0.5)\n",
    "        F1_scores.append((2* (mean(precision) * mean(recalls)))/(mean(precision) + mean(recalls)))\n",
    "        APs.append(AP)\n",
    "        PRECISION.append(precision)\n",
    "        RECALL.append(recalls)\n",
    "        OVERLAPS.append(overlaps)\n",
    "        class_id.append(gt_class_id)\n",
    "        \n",
    "    mAP = mean(APs)\n",
    "    return mAP, APs, F1_scores, PRECISION, RECALL, OVERLAPS, class_id \n",
    "\n",
    "\n",
    "test_set = ClownDataset()\n",
    "\n",
    "\n",
    "\n",
    "# get mAP, precision, recall, F1 (per bb in an images)\n",
    "def generateMetrics(path):\n",
    "    test_set = ClownDataset()\n",
    "    test_set.load_dataset(path, is_train=False)\n",
    "    test_set.prepare()\n",
    "    cfg = PredictionConfig()\n",
    "    model = MaskRCNN(mode = 'inference', model_dir = './', config = cfg)\n",
    "    model.load_weights('/home/ubuntu/Mask_RCNN/models/clown_human_ballin_100epoch/mask_rcnn_clown_cfg_0100.h5', by_name = True)\n",
    "    test_mAP = evaluate_model(test_set, model, cfg)\n",
    "\n",
    "    files = []\n",
    "    for m in test_set.image_from_source_map:\n",
    "        files.append(m)\n",
    "\n",
    "    aps = []\n",
    "    for ap in test_mAP[1]:\n",
    "        aps.append(ap)\n",
    "\n",
    "    f1s = []\n",
    "    for f1 in test_mAP[2]:\n",
    "        f1s.append(f1)\n",
    "\n",
    "    PRECISION = []\n",
    "    for p in test_mAP[3]:\n",
    "        PRECISION.append(p)\n",
    "\n",
    "    RECALL = []\n",
    "    for r in test_mAP[4]:\n",
    "        RECALL.append(r)\n",
    "\n",
    "    OVERLAPS = []\n",
    "    for o in test_mAP[5]:\n",
    "        OVERLAPS.append(o)\n",
    "\n",
    "    class_id = []\n",
    "    for c in test_mAP[6]:\n",
    "        class_id.append(c)\n",
    "    \n",
    "    df = pd.DataFrame({'files':files, 'AP':aps, 'F1':f1s, 'class_id':class_id,'PRECISION':PRECISION, \n",
    "                       'RECALL':RECALL, 'OVERLAPS':OVERLAPS})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# read how many files vs. results \n",
    "def getNumberofInstance(path, modelUse, dataUse):\n",
    "    epoch1, epoch25, epoch50, epoch75, epoch100 = [], [], [], [], []\n",
    "    pre_pos_files = os.listdir(path)\n",
    "    for file in pre_pos_files:\n",
    "        if file.endswith('_0001.h5.jpg'):\n",
    "            epoch1.append(file)\n",
    "        elif file.endswith('_0025.h5.jpg'):\n",
    "            epoch25.append(file)\n",
    "        elif file.endswith('_0050.h5.jpg'):\n",
    "            epoch50.append(file)\n",
    "        elif file.endswith('_0075.h5.jpg'):\n",
    "            epoch75.append(file)\n",
    "        elif file.endswith('_0100.h5.jpg'):\n",
    "            epoch100.append(file)\n",
    "\n",
    "    df = pd.DataFrame({modelUse:[dataUse], \"epoch1\":len(epoch1), \"epoch25\":len(epoch25), \"epoch50\":len(epoch50), \n",
    "                       \"epoch75\":len(epoch75), \"epoch100\":[len(epoch100)]})\n",
    "    return(df)\n",
    "\n",
    "\n",
    "\n",
    "def TrueCount(path, modelUse, dataUse):\n",
    "    count = len(os.listdir(path))\n",
    "    df = pd.DataFrame({modelUse:[dataUse], \"TrueCount\":count})\n",
    "    return(df)\n",
    "\n",
    "\n",
    "def main():\n",
    "    PredPos_val = getNumberofInstance('/home/ubuntu/Mask_RCNN/data/validationDataBatchTest/outputMaskFrame', \n",
    "                                      \"set\",\"pred_pos_validation\")\n",
    "    \n",
    "    PredPos_train = getNumberofInstance('/home/ubuntu/Mask_RCNN/data/trainingDataBatchTest/outputMaskFrame', \n",
    "                                      \"set\",\"pred_pos_training\")\n",
    "    \n",
    "    PredTotal_val = getNumberofInstance('/home/ubuntu/Mask_RCNN/data/validationDataBatchTest/outputAllFrame', \n",
    "                                      \"set\",\"pred_tol_validation\")\n",
    "    \n",
    "    PredTotal_train = getNumberofInstance('/home/ubuntu/Mask_RCNN/data/trainingDataBatchTest/outputAllFrame', \n",
    "                                      \"set\",\"pred_tol_training\")\n",
    "    \n",
    "    prediction = pd.concat([PredPos_val, PredPos_train, PredTotal_val, PredTotal_train])\n",
    "    return prediction\n",
    "    \n",
    "def mainTrue():\n",
    "    \n",
    "    TruePos_val = TrueCount('/home/ubuntu/Mask_RCNN/data/validation - True', \n",
    "                                      \"set\",\"true_pos_validation\")\n",
    "    TruePos_Training = TrueCount('/home/ubuntu/Mask_RCNN/data/training - True', \n",
    "                                      \"set\",\"true_pos_training\")\n",
    "    \n",
    "    gTrue = pd.concat([TruePos_val, TruePos_Training])\n",
    "    \n",
    "    return gTrue\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    res = main()\n",
    "    resTrue = mainTrue()\n",
    "    Output = res.append(resTrue).T\n",
    "    Output.columns = Output.iloc[0]\n",
    "    Output = Output.drop([\"set\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrics based on # of images (each image evaluation)\n",
    "\n",
    "def TruefilesNumber(pathtoIndex, pathTrueImage, DataUse):\n",
    "    \n",
    "    fileassign = generateMetrics(pathtoIndex)\n",
    "    fileassign['imageID'] = fileassign.index\n",
    "    IndexFiles = fileassign[['imageID', 'files']]\n",
    "    IndexFiles['files'] = IndexFiles['files'].str.replace('dataset.',\"\")\n",
    "\n",
    "    TrueFileConvert = []\n",
    "    TrueFiles = os.listdir(pathTrueImage)\n",
    "    for f in TrueFiles:\n",
    "        TrueFileConvert.append(f.split(\".\")[0])\n",
    "    Truefile = pd.DataFrame({'files': TrueFileConvert})\n",
    "\n",
    "    f = pd.merge(IndexFiles, Truefile, on=\"files\", how='inner')\n",
    "    f[DataUse] = 'TruePositive'\n",
    "    \n",
    "    return f\n",
    "\n",
    "def mainVal():\n",
    "    val = TruefilesNumber('/home/ubuntu/Mask_RCNN/data/validation', '/home/ubuntu/Mask_RCNN/data/validation - True',\n",
    "                    'validation')\n",
    "    return val\n",
    "    \n",
    "def mainTrain():\n",
    "    train = TruefilesNumber('/home/ubuntu/Mask_RCNN/data/training', '/home/ubuntu/Mask_RCNN/data/training - True','training')\n",
    "    \n",
    "    return train\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TrueVal = mainVal()\n",
    "    TrueTrain = mainTrain()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def runningFiles(pathtooutput):\n",
    "    ID, epoch = [], []\n",
    "    files = os.listdir(pathtooutput)\n",
    "    for file in files:\n",
    "        ID.append(file.split('_')[0])\n",
    "        epoch.append(file.split('_')[5].split('.')[0])\n",
    "    inFile = pd.DataFrame({\"imageID\": ID, \"Epoch\": epoch})\n",
    "    return inFile\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    PredTrianAllfiles = runningFiles('/home/ubuntu/Mask_RCNN/data/trainingDataBatchTest/outputAllFrame')\n",
    "    PredValAllfiles = runningFiles('/home/ubuntu/Mask_RCNN/data/validationDataBatchTest/outputAllFrame')\n",
    "    PredTrianPosfiles = runningFiles('/home/ubuntu/Mask_RCNN/data/trainingDataBatchTest/outputMaskFrame')\n",
    "    PredValPosfiles = runningFiles('/home/ubuntu/Mask_RCNN/data/validationDataBatchTest/outputMaskFrame')\n",
    "\n",
    "# Validation\n",
    "PredValPosfiles['validation'] = 'PredPositive'\n",
    "vali = pd.merge(PredValAllfiles, PredValPosfiles, on=['imageID', 'Epoch'], how='outer')  \n",
    "vali = vali.fillna('PredNegative')\n",
    "listTrueVal = [str(i) for i in list(TrueVal['imageID'])]\n",
    "PreVal = vali[vali['imageID'].isin(listTrueVal)]\n",
    "PreVal['validation_Truth'] = 'TruePostive'\n",
    "PreValf = vali[~vali['imageID'].isin(listTrueVal)]\n",
    "PreValf['validation_Truth'] = 'TrueNegative'\n",
    "ValidationData = pd.concat([PreVal, PreValf])\n",
    "\n",
    "ep, pp, pn, np, nn = [], [], [],[], []\n",
    "for e in ValidationData['Epoch'].unique():   \n",
    "    ValidationData1 = ValidationData.groupby(['Epoch']).get_group(e)\n",
    "    pp.append(len(ValidationData1[(ValidationData1['validation']=='PredPositive') \n",
    "                                      &(ValidationData1['validation_Truth']=='TruePostive')]))\n",
    "    pn.append(len(ValidationData1[(ValidationData1['validation']=='PredPositive') \n",
    "                                      &(ValidationData1['validation_Truth']=='TrueNegative')]))\n",
    "    np.append(len(ValidationData1[(ValidationData1['validation']=='PredNegative') \n",
    "                                      &(ValidationData1['validation_Truth']=='TruePostive')]))\n",
    "    nn.append(len(ValidationData1[(ValidationData1['validation']=='PredNegative') \n",
    "                                      &(ValidationData1['validation_Truth']=='TrueNegative')]))\n",
    "    ep.append(e)\n",
    "    \n",
    "    validationMatrix = pd.DataFrame({'Epoch':ep, 'PrePos_TruePos': pp, 'PrePos_TrueNeg': pn, 'PreNeg_TruePos': np,\n",
    "                                    'PreNeg_TrueNeg': nn})\n",
    "    \n",
    "validationMatrix.sort_values(by=['Epoch'])\n",
    "\n",
    "# Training \n",
    "PredTrianPosfiles['validation'] = 'PredPositive'\n",
    "train = pd.merge(PredTrianAllfiles, PredTrianPosfiles, on=['imageID', 'Epoch'], how='outer')  \n",
    "tr = train.fillna('PredNegative')\n",
    "listtTrueVal = [str(i) for i in list(TrueTrain['imageID'])]\n",
    "PreTrain = tr[tr['imageID'].isin(listtTrueVal)]\n",
    "PreTrain['training_Truth'] = 'TruePostive'\n",
    "PreTrainf = tr[~tr['imageID'].isin(listtTrueVal)]\n",
    "PreTrainf['training_Truth'] = 'TrueNegative'\n",
    "TrainingData = pd.concat([PreTrain, PreTrainf])\n",
    "\n",
    "ep, pp, pn, np, nn = [], [], [],[], []\n",
    "for e in TrainingData['Epoch'].unique():   \n",
    "    TrainingData1 = TrainingData.groupby(['Epoch']).get_group(e)\n",
    "    pp.append(len(TrainingData1[(TrainingData1['validation']=='PredPositive') \n",
    "                                      &(TrainingData1['training_Truth']=='TruePostive')]))\n",
    "    pn.append(len(TrainingData1[(TrainingData1['validation']=='PredPositive') \n",
    "                                      &(TrainingData1['training_Truth']=='TrueNegative')]))\n",
    "    np.append(len(TrainingData1[(TrainingData1['validation']=='PredNegative') \n",
    "                                      &(TrainingData1['training_Truth']=='TruePostive')]))\n",
    "    nn.append(len(TrainingData1[(TrainingData1['validation']=='PredNegative') \n",
    "                                      &(TrainingData1['training_Truth']=='TrueNegative')]))\n",
    "    ep.append(e)\n",
    "    \n",
    "    TrainingMatrix = pd.DataFrame({'Epoch':ep, 'PrePos_TruePos': pp, 'PrePos_TrueNeg': pn, 'PreNeg_TruePos': np,\n",
    "                                    'PreNeg_TrueNeg': nn})\n",
    "    \n",
    "TrainingMatrix.sort_values(by=['Epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the results\n",
    "Output.to_csv('/home/ubuntu/Mask_RCNN/data/outputMetrics/totalNumberImages.txt')\n",
    "TrainingMatrix.to_csv('/home/ubuntu/Mask_RCNN/data/outputMetrics/TrainingMatrix.txt')\n",
    "validationMatrix.to_csv('/home/ubuntu/Mask_RCNN/data/outputMetrics/validationMatrix.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
