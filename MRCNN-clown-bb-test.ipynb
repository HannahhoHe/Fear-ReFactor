{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "import pandas as pd\n",
    "sys.path.append('/home/ubuntu/Mask_RCNN/samples/coco') \n",
    "import coco\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 17\n"
     ]
    }
   ],
   "source": [
    "# 2 classes - clown & others\n",
    "\n",
    "class ClownDataset(Dataset):\n",
    "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
    "\t\tself.add_class(\"dataset\", 1, \"clown\")\n",
    "\t\tself.add_class(\"dataset\", 2, \"others\")   \n",
    "\t\timages_dir = dataset_dir + '/images/'\n",
    "\t\tannotations_dir = dataset_dir + '/annots/'\n",
    "\t\tfor filename in listdir(images_dir):\n",
    "\t\t\timage_id = filename[:-4]\n",
    "\t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path, class_ids=[0,1,2])\n",
    "\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\ttree = ElementTree.parse(filename)\n",
    "\t\troot = tree.getroot()\n",
    "\t\tboxes = list()\n",
    "\t\tfor box in root.findall('.//bndbox'):\n",
    "\t\t\txmin = int(box.find('xmin').text)\n",
    "\t\t\tymin = int(box.find('ymin').text)\n",
    "\t\t\txmax = int(box.find('xmax').text)\n",
    "\t\t\tymax = int(box.find('ymax').text)\n",
    "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
    "\t\t\tboxes.append(coors)\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    "\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\tpath = info['annotation']\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tif i == 0:                                    \n",
    "\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1                   \n",
    "\t\t\t\tclass_ids.append(self.class_names.index('clown'))      \n",
    "\t\t\telse:                                         \n",
    "\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 2                 \n",
    "\t\t\t\tclass_ids.append(self.class_names.index('others'))    \n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')                \n",
    "\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']\n",
    "\n",
    "class PredictionConfig(Config):\n",
    "\tNAME = \"Clown_cfg\"\n",
    "\tNUM_CLASSES = 1 + 2\n",
    "\tGPU_COUNT = 1\n",
    "\tIMAGES_PER_GPU = 1\n",
    "\n",
    "\n",
    "def evaluate_model(dataset, model, cfg):\n",
    "    APs = list();\n",
    "    F1_scores = list();\n",
    "    PRECISION = list();\n",
    "    RECALL = list();\n",
    "    OVERLAPS = list();\n",
    "    class_id = list(); \n",
    "    \n",
    "    for image_id in dataset.image_ids:\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
    "        scaled_image = mold_image(image, cfg)\n",
    "        sample = expand_dims(scaled_image, 0)\n",
    "        yhat = model.detect(sample, verbose=0)\n",
    "        r = yhat[0]\n",
    "        AP, precision, recalls, overlaps = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'],\n",
    "                                iou_threshold=0.5)\n",
    "        F1_scores.append((2* (mean(precision) * mean(recalls)))/(mean(precision) + mean(recalls)))\n",
    "        APs.append(AP)\n",
    "        PRECISION.append(precision)\n",
    "        RECALL.append(recalls)\n",
    "        OVERLAPS.append(overlaps)\n",
    "        class_id.append(gt_class_id)\n",
    "        \n",
    "    mAP = mean(APs)\n",
    "    return mAP, APs, F1_scores, PRECISION, RECALL, OVERLAPS, class_id \n",
    "\n",
    "\n",
    "test_set = ClownDataset()\n",
    "test_set.load_dataset('/home/ubuntu/Mask_RCNN/data/validation', is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))\n",
    "cfg = PredictionConfig()\n",
    "model = MaskRCNN(mode = 'inference', model_dir = './', config = cfg)\n",
    "\n",
    "model.load_weights('/home/ubuntu/Mask_RCNN/models/clown_human_ballin_100epoch/mask_rcnn_clown_cfg_0100.h5', by_name = True)\n",
    "test_mAP = evaluate_model(test_set, model, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mAP, precision, recall, F1 (not applicable in this project)\n",
    "def generateMetrics(path):\n",
    "    test_set = ClownDataset()\n",
    "    test_set.load_dataset(path, is_train=False)\n",
    "    test_set.prepare()\n",
    "    cfg = PredictionConfig()\n",
    "    model = MaskRCNN(mode = 'inference', model_dir = './', config = cfg)\n",
    "    model.load_weights('/home/ubuntu/Mask_RCNN/models/clown_human_ballin_100epoch/mask_rcnn_clown_cfg_0100.h5', by_name = True)\n",
    "    test_mAP = evaluate_model(test_set, model, cfg)\n",
    "\n",
    "    files = []\n",
    "    for m in test_set.image_from_source_map:\n",
    "        files.append(m)\n",
    "\n",
    "    aps = []\n",
    "    for ap in test_mAP[1]:\n",
    "        aps.append(ap)\n",
    "\n",
    "    f1s = []\n",
    "    for f1 in test_mAP[2]:\n",
    "        f1s.append(f1)\n",
    "\n",
    "    PRECISION = []\n",
    "    for p in test_mAP[3]:\n",
    "        PRECISION.append(p)\n",
    "\n",
    "    RECALL = []\n",
    "    for r in test_mAP[4]:\n",
    "        RECALL.append(r)\n",
    "\n",
    "    OVERLAPS = []\n",
    "    for o in test_mAP[5]:\n",
    "        OVERLAPS.append(o)\n",
    "\n",
    "    class_id = []\n",
    "    for c in test_mAP[6]:\n",
    "        class_id.append(c)\n",
    "    \n",
    "    df = pd.DataFrame({'files':files, 'AP':aps, 'F1':f1s, 'class_id':class_id,'PRECISION':PRECISION, \n",
    "                       'RECALL':RECALL, 'OVERLAPS':OVERLAPS})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read how many files vs. results \n",
    "\n",
    "def getNumberofInstance(path, modelUse, dataUse):\n",
    "    epoch1, epoch25, epoch50, epoch75, epoch100 = [], [], [], [], []\n",
    "    pre_pos_files = os.listdir(path)\n",
    "    for file in pre_pos_files:\n",
    "        if file.endswith('_0001.h5.jpg'):\n",
    "            epoch1.append(file)\n",
    "        elif file.endswith('_0025.h5.jpg'):\n",
    "            epoch25.append(file)\n",
    "        elif file.endswith('_0050.h5.jpg'):\n",
    "            epoch50.append(file)\n",
    "        elif file.endswith('_0075.h5.jpg'):\n",
    "            epoch75.append(file)\n",
    "        elif file.endswith('_0100.h5.jpg'):\n",
    "            epoch100.append(file)\n",
    "\n",
    "    df = pd.DataFrame({modelUse:[dataUse], \"epoch1\":len(epoch1), \"epoch25\":len(epoch25), \"epoch50\":len(epoch50), \n",
    "                       \"epoch75\":len(epoch75), \"epoch100\":[len(epoch100)]})\n",
    "    return(df)\n",
    "\n",
    "\n",
    "\n",
    "def TrueCount(path, modelUse, dataUse):\n",
    "    count = len(os.listdir(path))\n",
    "    df = pd.DataFrame({modelUse:[dataUse], \"TrueCount\":count})\n",
    "    return(df)\n",
    "\n",
    "\n",
    "def main():\n",
    "    PredPos_val = getNumberofInstance('/home/ubuntu/Mask_RCNN/data/validationDataBatchTest/outputMaskFrame', \n",
    "                                      \"set\",\"pred_pos_validation\")\n",
    "    \n",
    "    PredPos_train = getNumberofInstance('/home/ubuntu/Mask_RCNN/data/trainingDataBatchTest/outputMaskFrame', \n",
    "                                      \"set\",\"pred_pos_training\")\n",
    "    \n",
    "    PredTotal_val = getNumberofInstance('/home/ubuntu/Mask_RCNN/data/validationDataBatchTest/outputAllFrame', \n",
    "                                      \"set\",\"pred_tol_validation\")\n",
    "    \n",
    "    PredTotal_train = getNumberofInstance('/home/ubuntu/Mask_RCNN/data/trainingDataBatchTest/outputAllFrame', \n",
    "                                      \"set\",\"pred_tol_training\")\n",
    "    \n",
    "    prediction = pd.concat([PredPos_val, PredPos_train, PredTotal_val, PredTotal_train])\n",
    "    return prediction\n",
    "    \n",
    "def mainTrue():\n",
    "    \n",
    "    TruePos_val = TrueCount('/home/ubuntu/Mask_RCNN/data/validation - True', \n",
    "                                      \"set\",\"true_pos_validation\")\n",
    "    TruePos_Training = TrueCount('/home/ubuntu/Mask_RCNN/data/training - True', \n",
    "                                      \"set\",\"true_pos_training\")\n",
    "    \n",
    "    gTrue = pd.concat([TruePos_val, TruePos_Training])\n",
    "    \n",
    "    return gTrue\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    res = main()\n",
    "    resTrue = mainTrue()\n",
    "    Output = res.append(resTrue).T\n",
    "    Output.columns = Output.iloc[0]\n",
    "    Output = Output.drop([\"set\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>set</th>\n",
       "      <th>pred_pos_validation</th>\n",
       "      <th>pred_pos_training</th>\n",
       "      <th>pred_tol_validation</th>\n",
       "      <th>pred_tol_training</th>\n",
       "      <th>true_pos_validation</th>\n",
       "      <th>true_pos_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>epoch1</th>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>17</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch25</th>\n",
       "      <td>11</td>\n",
       "      <td>57</td>\n",
       "      <td>17</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch50</th>\n",
       "      <td>10</td>\n",
       "      <td>58</td>\n",
       "      <td>17</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch75</th>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>17</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch100</th>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>17</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TrueCount</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "set       pred_pos_validation pred_pos_training pred_tol_validation  \\\n",
       "epoch1                     16                64                  17   \n",
       "epoch25                    11                57                  17   \n",
       "epoch50                    10                58                  17   \n",
       "epoch75                    15                64                  17   \n",
       "epoch100                   16                64                  17   \n",
       "TrueCount                 NaN               NaN                 NaN   \n",
       "\n",
       "set       pred_tol_training true_pos_validation true_pos_training  \n",
       "epoch1                   65                 NaN               NaN  \n",
       "epoch25                  65                 NaN               NaN  \n",
       "epoch50                  65                 NaN               NaN  \n",
       "epoch75                  65                 NaN               NaN  \n",
       "epoch100                 65                 NaN               NaN  \n",
       "TrueCount               NaN                   7                50  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the filenames of True images\n",
    "\n",
    "def TruefilesNumber(pathtoIndex, pathTrueImage, DataUse):\n",
    "    \n",
    "    fileassign = generateMetrics(pathtoIndex)\n",
    "    fileassign['imageID'] = fileassign.index\n",
    "    IndexFiles = fileassign[['imageID', 'files']]\n",
    "    IndexFiles['files'] = IndexFiles['files'].str.replace('dataset.',\"\")\n",
    "\n",
    "    TrueFileConvert = []\n",
    "    TrueFiles = os.listdir(pathTrueImage)\n",
    "    for f in TrueFiles:\n",
    "        TrueFileConvert.append(f.split(\".\")[0])\n",
    "    Truefile = pd.DataFrame({'files': TrueFileConvert})\n",
    "\n",
    "    f = pd.merge(IndexFiles, Truefile, on=\"files\", how='inner')\n",
    "    f[DataUse] = 'TruePositive'\n",
    "    \n",
    "    return f\n",
    "\n",
    "def mainVal():\n",
    "    val = TruefilesNumber('/home/ubuntu/Mask_RCNN/data/validation', '/home/ubuntu/Mask_RCNN/data/validation - True',\n",
    "                    'validation')\n",
    "    return val\n",
    "    \n",
    "def mainTrain():\n",
    "    train = TruefilesNumber('/home/ubuntu/Mask_RCNN/data/training', '/home/ubuntu/Mask_RCNN/data/training - True','training')\n",
    "    \n",
    "    return train\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TrueVal = mainVal()\n",
    "    TrueTrain = mainTrain()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runningFiles(pathtooutput):\n",
    "    ID, epoch = [], []\n",
    "    files = os.listdir(pathtooutput)\n",
    "    for file in files:\n",
    "        ID.append(file.split('_')[0])\n",
    "        epoch.append(file.split('_')[5].split('.')[0])\n",
    "    inFile = pd.DataFrame({\"imageID\": ID, \"Epoch\": epoch})\n",
    "    return inFile\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    PredTrianAllfiles = runningFiles('/home/ubuntu/Mask_RCNN/data/trainingDataBatchTest/outputAllFrame')\n",
    "    PredValAllfiles = runningFiles('/home/ubuntu/Mask_RCNN/data/validationDataBatchTest/outputAllFrame')\n",
    "    PredTrianPosfiles = runningFiles('/home/ubuntu/Mask_RCNN/data/trainingDataBatchTest/outputMaskFrame')\n",
    "    PredValPosfiles = runningFiles('/home/ubuntu/Mask_RCNN/data/validationDataBatchTest/outputMaskFrame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "PredValPosfiles['validation'] = 'PredPositive'\n",
    "vali = pd.merge(PredValAllfiles, PredValPosfiles, on=['imageID', 'Epoch'], how='outer')  \n",
    "vali = vali.fillna('PredNegative')\n",
    "listTrueVal = [str(i) for i in list(TrueVal['imageID'])]\n",
    "PreVal = vali[vali['imageID'].isin(listTrueVal)]\n",
    "PreVal['validation_Truth'] = 'TruePostive'\n",
    "PreValf = vali[~vali['imageID'].isin(listTrueVal)]\n",
    "PreValf['validation_Truth'] = 'TrueNegative'\n",
    "ValidationData = pd.concat([PreVal, PreValf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training \n",
    "PredTrianPosfiles['validation'] = 'PredPositive'\n",
    "train = pd.merge(PredTrianAllfiles, PredTrianPosfiles, on=['imageID', 'Epoch'], how='outer')  \n",
    "tr = train.fillna('PredNegative')\n",
    "listtTrueVal = [str(i) for i in list(TrueTrain['imageID'])]\n",
    "PreTrain = tr[tr['imageID'].isin(listtTrueVal)]\n",
    "PreTrain['training_Truth'] = 'TruePostive'\n",
    "PreTrainf = tr[~tr['imageID'].isin(listtTrueVal)]\n",
    "PreTrainf['training_Truth'] = 'TrueNegative'\n",
    "TrainingData = pd.concat([PreTrain, PreTrainf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0100 7 9 0 1\n",
      "0050 7 3 0 7\n",
      "0001 7 9 0 1\n",
      "0025 7 4 0 6\n",
      "0075 7 8 0 2\n"
     ]
    }
   ],
   "source": [
    "for e in ValidationData['Epoch'].unique():   \n",
    "    ValidationData1 = ValidationData.groupby(['Epoch']).get_group(e)\n",
    "    PredPos_TruePost = len(ValidationData1[(ValidationData1['validation']=='PredPositive') \n",
    "                                      &(ValidationData1['validation_Truth']=='TruePostive')])\n",
    "    PredPos_TrueNeg = len(ValidationData1[(ValidationData1['validation']=='PredPositive') \n",
    "                                      &(ValidationData1['validation_Truth']=='TrueNegative')])\n",
    "    PredNeg_TruePos = len(ValidationData1[(ValidationData1['validation']=='PredNegative') \n",
    "                                      &(ValidationData1['validation_Truth']=='TruePostive')])\n",
    "    PredNeg_TrueNeg = len(ValidationData1[(ValidationData1['validation']=='PredNegative') \n",
    "                                      &(ValidationData1['validation_Truth']=='TrueNegative')])\n",
    "    print(e, PredPos_TruePost,PredPos_TrueNeg, PredNeg_TruePos, PredNeg_TrueNeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001 50 14 0 1\n",
      "0050 47 11 3 4\n",
      "0025 46 11 4 4\n",
      "0100 50 14 0 1\n",
      "0075 50 14 0 1\n"
     ]
    }
   ],
   "source": [
    "for e in TrainingData['Epoch'].unique():   \n",
    "    TrainingData1 = TrainingData.groupby(['Epoch']).get_group(e)\n",
    "    PredPos_TruePost = len(TrainingData1[(TrainingData1['validation']=='PredPositive') \n",
    "                                      &(TrainingData1['training_Truth']=='TruePostive')])\n",
    "    PredPos_TrueNeg = len(TrainingData1[(TrainingData1['validation']=='PredPositive') \n",
    "                                      &(TrainingData1['training_Truth']=='TrueNegative')])\n",
    "    PredNeg_TruePos = len(TrainingData1[(TrainingData1['validation']=='PredNegative') \n",
    "                                      &(TrainingData1['training_Truth']=='TruePostive')])\n",
    "    PredNeg_TrueNeg = len(TrainingData1[(TrainingData1['validation']=='PredNegative') \n",
    "                                      &(TrainingData1['training_Truth']=='TrueNegative')])\n",
    "    \n",
    "    print(e, PredPos_TruePost,PredPos_TrueNeg, PredNeg_TruePos, PredNeg_TrueNeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
