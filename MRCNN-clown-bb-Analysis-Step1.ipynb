{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "import pandas as pd\n",
    "sys.path.append('/home/ubuntu/Mask_RCNN/samples/coco') \n",
    "import coco\n",
    "%matplotlib inline\n",
    "import re\n",
    "import itertools \n",
    "\n",
    "# Analysis of both training (below are # out) and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting all Files Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read xml annotation files vs. output object counts -- # objects per frame\n",
    "\n",
    "def getGroundTruthObjectCount(path):    \n",
    "    df_annotation = pd.read_csv(path)\n",
    "    df_annotation = df_annotation.drop(columns='Unnamed: 0')\n",
    "    df_annotation_count = df_annotation.pivot_table(index = 'imageID', columns='annot_objs', aggfunc= lambda x:len(x)).fillna(0)\n",
    "    #df_annotation_count = df_annotation_count.drop(columns='w')\n",
    "    return df_annotation_count\n",
    "\n",
    "\n",
    "def getPredObjectCount(path):\n",
    "    ObjCount_files = os.listdir(path)\n",
    "\n",
    "    a, b, c, d = [], [], [], []\n",
    "    for file in ObjCount_files:\n",
    "        if file.endswith('_0005.h5.txt'):\n",
    "            each_file = pd.read_csv(path + file)\n",
    "            each_file['ImageID'] = file.replace('_mask_rcnn_clown_cfg_0005.h5.txt','')\n",
    "            each_file['epoch'] = '0005'\n",
    "            a.append(each_file)\n",
    "            df_a = pd.concat(a)\n",
    "            df_a = df_a.drop(columns={'Unnamed: 0', 'image'})\n",
    "\n",
    "        elif file.endswith('_0015.h5.txt'):\n",
    "            each_file = pd.read_csv(path + file)\n",
    "            each_file['ImageID'] = file.replace('_mask_rcnn_clown_cfg_0015.h5.txt','')\n",
    "            each_file['epoch'] = '0015'\n",
    "            b.append(each_file)\n",
    "            df_b = pd.concat(b)\n",
    "            df_b = df_b.drop(columns={'Unnamed: 0', 'image'})\n",
    "\n",
    "\n",
    "        elif file.endswith('_0025.h5.txt'):\n",
    "            each_file = pd.read_csv(path + file)\n",
    "            each_file['ImageID'] = file.replace('_mask_rcnn_clown_cfg_0025.h5.txt','')\n",
    "            each_file['epoch'] = '0025'\n",
    "            c.append(each_file)\n",
    "            df_c = pd.concat(c)\n",
    "            df_c = df_c.drop(columns={'Unnamed: 0', 'image'})\n",
    "\n",
    "\n",
    "        elif file.endswith('_0038.h5.txt'):\n",
    "            each_file = pd.read_csv(path + file)\n",
    "            each_file['ImageID'] = file.replace('_mask_rcnn_clown_cfg_0038.h5.txt','')\n",
    "            each_file['epoch'] = '0038'\n",
    "            d.append(each_file)\n",
    "            df_d = pd.concat(d)\n",
    "            df_d = df_d.drop(columns={'Unnamed: 0', 'image'})\n",
    "\n",
    "    df_OutObj = pd.concat([df_a, df_b, df_c, df_d])\n",
    "    return df_OutObj\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    #df_groundTruthTraining = getGroundTruthObjectCount('/home/ubuntu/Mask_RCNN/data/trainingAnnotation.txt')\n",
    "    #df_groundTruthTraining.reset_index(inplace=True)\n",
    "    #df_groundTruthTraining['files'] = df_groundTruthTraining['imageID']\n",
    "    #df_groundTruthTraining = df_groundTruthTraining.drop(columns={'w', \"imageID\"})\n",
    "    #df_groundTruthTraining['files'] = df_groundTruthTraining['files'].str.replace('.xml','')\n",
    "    #df_groundTruthTraining.to_csv('/home/ubuntu/Mask_RCNN/data/reform_trainingAnnotation.txt')\n",
    "    \n",
    "    df_groundTruthVal = getGroundTruthObjectCount('/home/ubuntu/Mask_RCNN/data/testingAnnotation.txt')\n",
    "    df_groundTruthVal.reset_index(inplace=True)\n",
    "    df_groundTruthVal['files'] = df_groundTruthVal['imageID']\n",
    "    df_groundTruthVal = df_groundTruthVal.drop(columns={\"imageID\"})\n",
    "    df_groundTruthVal['files'] = df_groundTruthVal['files'].str.replace('.xml','')\n",
    "    df_groundTruthVal.to_csv('/home/ubuntu/Mask_RCNN/data/reform_testingAnnotation.txt')\n",
    "    \n",
    "    #df_PredTraining = getPredObjectCount('/home/ubuntu/Mask_RCNN/data/TrainingResults/outputObjCount/')\n",
    "    #df_PredTraining.to_csv('/home/ubuntu/Mask_RCNN/data/reform_TrainingoutputObjCount.txt')\n",
    "    \n",
    "    df_PredVal = getPredObjectCount('/home/ubuntu/Mask_RCNN/data/outputObjCount/')\n",
    "    df_PredVal.to_csv('/home/ubuntu/Mask_RCNN/data/reform_TestingoutputObjCount.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# togethers - groundTruth vs. prediction (trainig set)- skip if there is no trainingset data \n",
    "df_index_training = pd.read_csv('/home/ubuntu/Mask_RCNN/data/TrainfilevsImageID.txt')\n",
    "df_index_training['files'] = df_index_training['files'].str.replace(\"dataset.\",'')\n",
    "df_index_training = df_index.rename(columns= {'Unnamed: 0':'imageID'})\n",
    "df_index_training['imageID'] = df_index_training['imageID'].replace('.xml', \"\")\n",
    "\n",
    "truth = pd.merge(df_groundTruthTraining, df_index_training, on = ['files'], how ='outer')\n",
    "truth = truth.rename(columns={'clown':'true_clown', 'color':'true_color', 'nface':'true_nface' })\n",
    "\n",
    "df_PredTraining = df_PredTraining.rename(columns = {'ImageID':'imageID'})\n",
    "\n",
    "all_file = []\n",
    "for e in df_PredTraining.epoch.unique():\n",
    "    dfsub = df_PredTraining[(df_PredTraining.epoch == e)]\n",
    "    dfsub['imageID'] = dfsub['imageID'].astype(int)\n",
    "    submerge = pd.merge(truth, dfsub, on=['imageID'], how='outer')\n",
    "    all_file.append(submerge)\n",
    "    \n",
    "df1 = all_file[0]\n",
    "df2 = all_file[1]\n",
    "df3 = all_file[2]\n",
    "df4 = all_file[3]\n",
    "training_truth_pred_objCount = pd.concat([df1, df2, df3, df4])\n",
    "training_truth_pred_objCount.to_csv('/home/ubuntu/Mask_RCNN/data/Training_truth_pred_objCount.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# togethers - groundTruth vs. prediction (validation set)\n",
    "df_index_testing = pd.read_csv('/home/ubuntu/Mask_RCNN/data/TestingfilevsImageID.txt')\n",
    "df_index_testing['files'] = df_index_testing['files'].str.replace(\"dataset.\",'')\n",
    "df_index_testing = df_index_testing.rename(columns= {'Unnamed: 0':'imageID'})\n",
    "df_index_testing['imageID'] = df_index_testing['imageID'].replace('.xml', \"\")\n",
    "\n",
    "\n",
    "truth_val = pd.merge(df_groundTruthVal, df_index_testing, on = ['files'], how ='outer')\n",
    "truth_val = truth_val.rename(columns={'clown':'val_clown', 'color':'val_color', 'nface':'val_nface' })\n",
    "\n",
    "df_PredVal = df_PredVal.rename(columns = {'ImageID':'imageID'})\n",
    "\n",
    "all_file_val = []\n",
    "for e in df_PredVal.epoch.unique():\n",
    "    dfsub_val = df_PredVal[(df_PredVal.epoch == e)]\n",
    "    dfsub_val['imageID'] = dfsub_val['imageID'].astype(int)\n",
    "    submerge_val = pd.merge(truth_val, dfsub_val, on=['imageID'], how='outer')\n",
    "    all_file_val.append(submerge_val)\n",
    "    \n",
    "df1_val = all_file_val[0]\n",
    "df2_val = all_file_val[1]\n",
    "df3_val = all_file_val[2]\n",
    "df4_val = all_file_val[3]\n",
    "testing_truth_pred_objCount = pd.concat([df1_val, df2_val, df3_val, df4_val])\n",
    "testing_truth_pred_objCount.to_csv('/home/ubuntu/Mask_RCNN/data/Testing_truth_pred_objCount.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Starts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNNPPTNNPforEpoch(data_file):\n",
    "\n",
    "    NN = data_file[(data_file.true_clown == 0.0) & (\n",
    "    data_file['#clown'] == 0.0)]\n",
    "\n",
    "    PP = data_file[(data_file.true_clown != 0.0) & (\n",
    "    data_file['#clown'] != 0.0)] \n",
    "\n",
    "    NP = data_file[(data_file.true_clown == 0.0) & (\n",
    "    data_file['#clown'] != 0.0)] \n",
    "\n",
    "    PN = data_file[(data_file.true_clown != 0.0) & (\n",
    "    data_file['#clown'] == 0.0)] \n",
    "\n",
    "    nn = NN.pivot_table(index='epoch', aggfunc = lambda x:len(x))\n",
    "    nn.reset_index(inplace=True)\n",
    "    try:\n",
    "        nn['NN'] = nn['#clown'] #use any\n",
    "        nn = nn.drop(columns={'#clown', '#nface', 'files', 'imageID', 'true_clown','true_color', 'true_nface'})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    pp = PP.pivot_table(index='epoch', aggfunc = lambda x:len(x))\n",
    "    pp.reset_index(inplace=True)\n",
    "    try:\n",
    "        pp['PP'] = pp['#clown'] #use any\n",
    "        pp = pp.drop(columns={'#clown', '#nface', 'files', 'imageID', 'true_clown','true_color', 'true_nface'})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    np = NP.pivot_table(index='epoch', aggfunc = lambda x:len(x))\n",
    "    np.reset_index(inplace=True)\n",
    "    try:\n",
    "        np['NP'] = np['#clown'] #use any\n",
    "        np = np.drop(columns={'#clown', '#nface', 'files', 'imageID', 'true_clown','true_color', 'true_nface'})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    pn = PN.pivot_table(index='epoch', aggfunc = lambda x:len(x))\n",
    "    pn.reset_index(inplace=True)\n",
    "    try:\n",
    "        pn['PN'] = pn['#clown'] #use any\n",
    "        pn = pn.drop(columns={'#clown', '#nface', 'files', 'imageID', 'true_clown','true_color', 'true_nface'})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    df_all = pd.concat([nn, pp, np, pn], axis = 1).drop_duplicates()\n",
    "    df_all = df_all.loc[:,~df_all.columns.duplicated()]\n",
    "    \n",
    "    return df_all\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # cut out google images \n",
    "    #training_truth_pred_objCount = training_truth_pred_objCount.sort_values(by=['files']).iloc[0:2464]\n",
    "    #df_training_PPNNPNNP_tabel = generateNNPPTNNPforEpoch(training_truth_pred_objCount)\n",
    "    #df_training_PPNNPNNP_tabel.to_csv('/home/ubuntu/Mask_RCNN/data/training_forConfusionTablePlot.txt')\n",
    "    \n",
    "   \n",
    "    testing_truth_pred_objCount = testing_truth_pred_objCount.rename(columns={'val_clown':'true_clown',\n",
    "                                           'val_color':'true_color',\n",
    "                                           'val_nface':'true_nface'}).fillna(0)\n",
    "    df_testing_PPNNPNNP_tabel = generateNNPPTNNPforEpoch(testing_truth_pred_objCount).fillna(0)\n",
    "    df_testing_PPNNPNNP_tabel.to_csv('/home/ubuntu/Mask_RCNN/data/testing_forConfusionTablePlot.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
