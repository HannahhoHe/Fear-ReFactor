{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import cv2\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from youtubesearchpython import SearchVideos\n",
    "from lxml import html, etree\n",
    "import pafy\n",
    "import json\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "sys.path.append('/home/ubuntu/Mask_RCNN/samples/coco') \n",
    "import coco\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import colorsys\n",
    "from skimage.measure import find_contours\n",
    "from matplotlib import patches,  lines\n",
    "from matplotlib.patches import Polygon\n",
    "import IPython.display\n",
    "from PIL import Image\n",
    "from mrcnn import visualize\n",
    "from ffpyplayer.player import MediaPlayer\n",
    "from pytube import YouTube\n",
    "from moviepy.editor import *\n",
    "from moviepy.video.VideoClip import VideoClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input\n",
    "\n",
    "#Website\n",
    "url = 'https://www.youtube.com/watch?v=GGOMD2DlJUY&t=1s'\n",
    "sec = 104 #which second to start \n",
    "fps = 30 #capture rate\n",
    "MaxCount = 5 #how many frames in total to parse = (start sec - end sec)*fps\n",
    "n_images = MaxCount # run in M-RCNN model\n",
    "\n",
    "video = pafy.new(url)\n",
    "bestResolutionVideo = video.getbest()\n",
    "bestResolutionVideo.download()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# video - to -images \n",
    "vidcap = cv2.VideoCapture(bestResolutionVideo.filename)\n",
    "def getFrame(sec):\n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)   #set the capturing start at (sec*1000 milliseconds)\n",
    "    hasFrames,image = vidcap.read()\n",
    "    if hasFrames:\n",
    "        SavePath = '/home/ubuntu/FobiaPhilter/ActionFiles/FramesFromVideo/images/'\n",
    "        cv2.imwrite(SavePath + \"image\"+str(count)+\".jpg\", image)     # save frame as JPG file\n",
    "    return hasFrames\n",
    "\n",
    "# audio edits\n",
    "def audio(sec, MaxCount):\n",
    "    a = sec\n",
    "    b = (MaxCount/30) + sec\n",
    "    audio_cut = VideoFileClip(bestResolutionVideo.filename).subclip(a,b)\n",
    "    audio_cut.write_videofile('audio.mp4', audio=True)\n",
    "\n",
    "\n",
    "# Run MRCNN \n",
    "\n",
    "class_names2 = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "           'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "           'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "           'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "           'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "           'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "           'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "           'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "           'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "           'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "           'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "          'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "          'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "           'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "           'teddy bear', 'hair drier', 'toothbrush'] \n",
    "\n",
    "class_names = ['BG', \"clown\", \"nface\", 'color'] \n",
    "\n",
    "\n",
    "# source code from visulaize.py\n",
    "def display_instances_cust(image, boxes, masks, class_ids, class_names,\n",
    "                      scores=None, title=\"\",\n",
    "                      figsize=(16, 16), ax=None,\n",
    "                      show_mask=True, show_bbox=True,\n",
    "                      colors=None, captions=None, imagecount=0):\n",
    "\n",
    "    # Number of instances\n",
    "    N = boxes.shape[0]\n",
    "    if not N:\n",
    "        print(\"\\n*** No instances to display *** \\n\")\n",
    "\n",
    "    # If no axis is passed, create one and automatically call show()\n",
    "    auto_show = False\n",
    "    if not ax:\n",
    "        _, ax = plt.subplots(1, figsize=figsize)\n",
    "        auto_show = True\n",
    "\n",
    "    # Generate random colors\n",
    "    colors = colors or random_colors(N)\n",
    "\n",
    "    # Show area outside image boundaries.\n",
    "    height, width = image.shape[:2]\n",
    "    ax.set_ylim(height + 0, -0)\n",
    "    ax.set_xlim(-0, width + 0)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    masked_image = image.astype(np.uint32).copy()\n",
    "    for i in range(N):\n",
    "        color = colors[i]\n",
    "\n",
    "        # Bounding box\n",
    "        if not np.any(boxes[i]):\n",
    "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
    "            continue\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        if show_bbox:\n",
    "            p = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,\n",
    "                                alpha=0.7, linestyle=\"dashed\",\n",
    "                                edgecolor=color, facecolor='none')\n",
    "            ax.add_patch(p)\n",
    "\n",
    "        # Label\n",
    "        class_id = class_ids[i]\n",
    "        label = class_names[class_id]\n",
    "        x = random.randint(x1, (x1 + x2) // 2)\n",
    "        caption = \"{}\".format(label)\n",
    "        #ax.text(x1, y1 + 8, caption,                               #if not showing text\n",
    "        #        color='b', size=20, backgroundcolor=\"none\")\n",
    "\n",
    "        # Mask\n",
    "        mask = masks[:, :, i]\n",
    "        if show_mask:                  \n",
    "            masked_image = apply_mask(masked_image, mask, color)   \n",
    "\n",
    "        # Mask Polygon\n",
    "        # Pad to ensure proper polygons for masks that touch image edges.\n",
    "        padded_mask = np.zeros(\n",
    "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
    "        padded_mask[1:-1, 1:-1] = mask\n",
    "        contours = find_contours(padded_mask, 0.5)\n",
    "        for verts in contours:\n",
    "            #Subtract the padding and flip (y, x) to (x, y)\n",
    "            verts = np.fliplr(verts) - 1\n",
    "            p = Polygon(verts, facecolor=\"none\", edgecolor='none')\n",
    "            ax.add_patch(p)\n",
    "            \n",
    "\n",
    "    ax.imshow(masked_image.astype(np.uint8))\n",
    "    plt.savefig(f\"/home/ubuntu/FobiaPhilter/ActionFiles/PostMRCNN/{imagecount}.jpg\", bbox_inches='tight', transparent = True, pad_inches=-0.5, \n",
    "                orientation= 'landscape')  #save output\n",
    "    if auto_show:\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        \n",
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    return colors\n",
    "     \n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == 1,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Begining the ClownDataset\n",
    "class ClownDataset(Dataset):\n",
    "    def load_dataset(self, dataset_dir, is_train=True):\n",
    "        self.add_class(\"dataset\", 1, \"clown\")\n",
    "        self.add_class(\"dataset\", 2, \"nface\")   \n",
    "        self.add_class(\"dataset\", 3, \"color\")   \n",
    "        images_dir = dataset_dir + '/images/'\n",
    "        annotations_dir = dataset_dir + '/annots/'\n",
    "        for filename in listdir(images_dir):\n",
    "            image_id = filename[:-4]\n",
    "            img_path = images_dir + filename\n",
    "            ann_path = annotations_dir + image_id + '.xml'\n",
    "            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path, class_ids=[0,1,2,3]) \n",
    "\n",
    "    def extract_boxes(self, filename):\n",
    "        tree = ElementTree.parse(filename)\n",
    "        root = tree.getroot()\n",
    "        boxes = list()\n",
    "        for box in root.findall('.//bndbox'):\n",
    "            xmin = int(box.find('xmin').text)\n",
    "            ymin = int(box.find('ymin').text)\n",
    "            xmax = int(box.find('xmax').text)\n",
    "            ymax = int(box.find('ymax').text)\n",
    "            coors = [xmin, ymin, xmax, ymax]\n",
    "            boxes.append(coors)\n",
    "        width = int(root.find('.//size/width').text)\n",
    "        height = int(root.find('.//size/height').text)\n",
    "        return boxes, width, height\n",
    "    \n",
    "    \n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        path = info['annotation']\n",
    "        boxes, w, h = self.extract_boxes(path)\n",
    "        masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "        class_ids = list()\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i]\n",
    "            row_s, row_e = box[1], box[3]\n",
    "            col_s, col_e = box[0], box[2]\n",
    "            if i == 0:                                    \n",
    "                masks[row_s:row_e, col_s:col_e, i] = 1                  \n",
    "                class_ids.append(self.class_names.index('clown'))      \n",
    "            elif i ==1:                                         \n",
    "                masks[row_s:row_e, col_s:col_e, i] = 2                 \n",
    "                class_ids.append(self.class_names.index('nface'))     \n",
    "            elif i ==2:                                         \n",
    "                masks[row_s:row_e, col_s:col_e, i] = 3                 \n",
    "                class_ids.append(self.class_names.index('color'))\n",
    "                \n",
    "        return masks, asarray(class_ids, dtype='int32')                \n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']\n",
    "\n",
    "    \n",
    "class PredictionConfig(Config):\n",
    "    NAME = \"Clown_cfg\"\n",
    "    NUM_CLASSES = 1 + 3\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    \n",
    "class InferenceConfig(coco.CocoConfig):  \n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    \n",
    "def check_for_overlap(rectangle_a, rectangle_b):\n",
    "    if(rectangle_a[0]>rectangle_b[2] or rectangle_a[1]>rectangle_b[3]):\n",
    "        a = 'n'\n",
    "    elif(rectangle_a[3]<rectangle_b[1] or rectangle_a[2]<rectangle_b[0]):\n",
    "        a = 'n'\n",
    "    else:\n",
    "        a = 'y'\n",
    "    return a\n",
    "        \n",
    "    \n",
    "def plot_predicted_new(dataset, model, model2, cfg, cfg2, class_names, class_names2, n_images): \n",
    "    for i in range(n_images):\n",
    "        image = dataset.load_image(i)\n",
    "        \n",
    "        #clown model \n",
    "        scaled_image = mold_image(image, cfg)\n",
    "        sample = expand_dims(scaled_image, 0)               \n",
    "        yhat = model.detect(sample, verbose=1)[0]     \n",
    "        r = yhat\n",
    "        \n",
    "                \n",
    "        #coco model \n",
    "        scaled_image = mold_image(image, cfg2)\n",
    "        sample = expand_dims(scaled_image, 0)               \n",
    "        yhat2 = model2.detect(sample, verbose=1)[0]     \n",
    "        r2 = yhat2\n",
    "        \n",
    "        \n",
    "        #condition\n",
    "        for k in range(r['masks'].shape[-1]):\n",
    "            if class_names[r['class_ids'][k]] == 'clown':\n",
    "                clownBox = r['rois'][k]\n",
    "                \n",
    "                for coco in range(r2['masks'].shape[-1]):\n",
    "                    if class_names2[r2['class_ids'][coco]] == 'person':\n",
    "                        try:\n",
    "                            if check_for_overlap(r['rois'][k], r2['rois'][coco])=='y':\n",
    "                                mask = r2['masks'][:, :, coco]\n",
    "                                image[mask] = 200\n",
    "                                \n",
    "                            else:\n",
    "                                pass\n",
    "                        except:\n",
    "                            pass\n",
    "                    else:\n",
    "                        pass\n",
    "                    \n",
    "            elif class_names[r['class_ids'][k]] != 'clown':\n",
    "                pass\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "        \n",
    "        display_instances_cust(image, r2['rois'], r2['masks'],  r2['class_ids'], class_names2, scores=False, imagecount=i,\n",
    "        show_bbox=False, captions=False, show_mask=False) \n",
    "        \n",
    "        \n",
    "def Modelmain():\n",
    "        test_set = ClownDataset()\n",
    "        test_set.load_dataset('/home/ubuntu/FobiaPhilter/ActionFiles/FramesFromVideo', is_train=False)\n",
    "        test_set.prepare()\n",
    "        cfg = PredictionConfig()  \n",
    "        \n",
    "        model_path = '/home/ubuntu/FobiaPhilter/ActionFiles/model/mask_rcnn_clown_cfg_0025.h5'\n",
    "        model = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n",
    "        model.load_weights(model_path, by_name=True)\n",
    "        \n",
    "        \n",
    "        cfg2 = InferenceConfig()\n",
    "        weights_path = '/home/ubuntu/FobiaPhilter/ActionFiles/model/mask_rcnn_coco.h5'\n",
    "        model2 = MaskRCNN(mode='inference', model_dir='./', config=cfg2)\n",
    "        model2.load_weights(weights_path, by_name=True)\n",
    "        plot_predicted_new(test_set, model, model2, cfg, cfg2, class_names, class_names2, n_images)\n",
    "        \n",
    "        \n",
    "        #Export imageID vs. original Filename\n",
    "        files = []\n",
    "        for m in test_set.image_from_source_map:\n",
    "            files.append(m)\n",
    "\n",
    "        df = pd.DataFrame({'Original_files':files})\n",
    "        df['Index_outputFile'] = df.index\n",
    "        df['Original_files'] = df['Original_files'].str.replace('dataset.image','').astype('int64')\n",
    "        df = df.sort_values(by=['Original_files'])\n",
    "        df.to_csv('/home/ubuntu/FobiaPhilter/ActionFiles/TestSampleImageID.txt')\n",
    "\n",
    "# convert images to videos\n",
    "def convertImageToVideo():\n",
    "    pathIn= '/home/ubuntu/FobiaPhilter/ActionFiles/PostMRCNN/'\n",
    "    pathOut = '/home/ubuntu/FobiaPhilter/ActionFiles/videoConstruct1.mp4'\n",
    "    df_filename_imageID = pd.read_csv('/home/ubuntu/FobiaPhilter/ActionFiles/TestSampleImageID.txt')\n",
    "    \n",
    "    frame_array = []\n",
    "    for file in df_filename_imageID['Index_outputFile']:\n",
    "        filename = pathIn + str(file) +'.jpg'\n",
    "        img = cv2.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        frame_array.append(img)\n",
    "    out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), 1/fps, size)\n",
    "    for i in range(len(frame_array)):\n",
    "        out.write(frame_array[i])\n",
    "    out.release()\n",
    "    \n",
    "    \n",
    "\n",
    "# To play video (! if running in aws, there won't be audio!)\n",
    "\n",
    "def playVideo():    \n",
    "    video_path = '/home/ubuntu/FobiaPhilter/ActionFiles/videoConstruct1.mp4' \n",
    "    audio_path = \"audio.mp4\"\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    player = MediaPlayer(audio_path)\n",
    "    while True:\n",
    "        grabbed, frame=video.read()\n",
    "        audio_frame, val = player.get_frame()\n",
    "        if not grabbed:\n",
    "            print(\"End of video\")\n",
    "            break\n",
    "        if cv2.waitKey(28) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "        if val != 'eof' and audio_frame is not None:\n",
    "            #audio\n",
    "            img, t = audio_frame\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sec = sec \n",
    "    count=1\n",
    "    success = getFrame(sec)\n",
    "    while success:\n",
    "        while (count < MaxCount):\n",
    "            count = count + 1   \n",
    "            sec = sec + (1/fps)*1    #every 1 frames\n",
    "            sec = round(sec, 2)\n",
    "            success = getFrame(sec)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    audio(sec, MaxCount)        \n",
    "    Modelmain()\n",
    "    convertImageToVideo()\n",
    "    #playVideo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
