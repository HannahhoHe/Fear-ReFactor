{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "import pandas as pd\n",
    "sys.path.append('/home/ubuntu/Mask_RCNN/samples/coco') \n",
    "import coco\n",
    "%matplotlib inline\n",
    "import re\n",
    "import itertools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not no previous run, starts here!\n",
    "# get total number of images in each dataset (training vs. validation: n, p)\n",
    "\n",
    "class ClownDataset(Dataset):\n",
    "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
    "\t\tself.add_class(\"dataset\", 1, \"clown\")\n",
    "\t\tself.add_class(\"dataset\", 2, \"others\")   \n",
    "\t\timages_dir = dataset_dir + '/images/'\n",
    "\t\tannotations_dir = dataset_dir + '/annots/'\n",
    "\t\tfor filename in listdir(images_dir):\n",
    "\t\t\timage_id = filename[:-4]\n",
    "\t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path, class_ids=[0,1,2])\n",
    "\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\ttree = ElementTree.parse(filename)\n",
    "\t\troot = tree.getroot()\n",
    "\t\tboxes = list()\n",
    "\t\tfor box in root.findall('.//bndbox'):\n",
    "\t\t\txmin = int(box.find('xmin').text)\n",
    "\t\t\tymin = int(box.find('ymin').text)\n",
    "\t\t\txmax = int(box.find('xmax').text)\n",
    "\t\t\tymax = int(box.find('ymax').text)\n",
    "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
    "\t\t\tboxes.append(coors)\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    "\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\tpath = info['annotation']\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tif i == 0:                                    \n",
    "\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1                   \n",
    "\t\t\t\tclass_ids.append(self.class_names.index('clown'))      \n",
    "\t\t\telse:                                         \n",
    "\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 2                 \n",
    "\t\t\t\tclass_ids.append(self.class_names.index('others'))    \n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')                \n",
    "\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']\n",
    "\n",
    "class PredictionConfig(Config):\n",
    "\tNAME = \"Clown_cfg\"\n",
    "\tNUM_CLASSES = 1 + 2\n",
    "\tGPU_COUNT = 1\n",
    "\tIMAGES_PER_GPU = 1\n",
    "\n",
    "\n",
    "def evaluate_model(dataset, model, cfg):\n",
    "    APs = list();\n",
    "    F1_scores = list();\n",
    "    PRECISION = list();\n",
    "    RECALL = list();\n",
    "    OVERLAPS = list();\n",
    "    class_id = list(); \n",
    "    \n",
    "    for image_id in dataset.image_ids:\n",
    "        image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
    "        scaled_image = mold_image(image, cfg)\n",
    "        sample = expand_dims(scaled_image, 0)\n",
    "        yhat = model.detect(sample, verbose=0)\n",
    "        r = yhat[0]\n",
    "        AP, precision, recalls, overlaps = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'],\n",
    "                                iou_threshold=0.5)\n",
    "        F1_scores.append((2* (mean(precision) * mean(recalls)))/(mean(precision) + mean(recalls)))\n",
    "        APs.append(AP)\n",
    "        PRECISION.append(precision)\n",
    "        RECALL.append(recalls)\n",
    "        OVERLAPS.append(overlaps)\n",
    "        class_id.append(gt_class_id)\n",
    "        \n",
    "    mAP = mean(APs)\n",
    "    return mAP, APs, F1_scores, PRECISION, RECALL, OVERLAPS, class_id \n",
    "\n",
    "\n",
    "test_set = ClownDataset()\n",
    "\n",
    "\n",
    "# get mAP, precision, recall, F1 (per bb in an images)\n",
    "\n",
    "def generateMetrics(path):\n",
    "    test_set = ClownDataset()\n",
    "    test_set.load_dataset(path, is_train=False)\n",
    "    test_set.prepare()\n",
    "    cfg = PredictionConfig()\n",
    "    model = MaskRCNN(mode = 'inference', model_dir = './', config = cfg)\n",
    "    model.load_weights('/home/ubuntu/Mask_RCNN/models/clown_human_ballin_100epoch/mask_rcnn_clown_cfg_0100.h5', by_name = True)\n",
    "    test_mAP = evaluate_model(test_set, model, cfg)\n",
    "\n",
    "    files = []\n",
    "    for m in test_set.image_from_source_map:\n",
    "        files.append(m)\n",
    "\n",
    "    aps = []\n",
    "    for ap in test_mAP[1]:\n",
    "        aps.append(ap)\n",
    "\n",
    "    f1s = []\n",
    "    for f1 in test_mAP[2]:\n",
    "        f1s.append(f1)\n",
    "\n",
    "    PRECISION = []\n",
    "    for p in test_mAP[3]:\n",
    "        PRECISION.append(p)\n",
    "\n",
    "    RECALL = []\n",
    "    for r in test_mAP[4]:\n",
    "        RECALL.append(r)\n",
    "\n",
    "    OVERLAPS = []\n",
    "    for o in test_mAP[5]:\n",
    "        OVERLAPS.append(o)\n",
    "\n",
    "    class_id = []\n",
    "    for c in test_mAP[6]:\n",
    "        class_id.append(c)\n",
    "    \n",
    "    df = pd.DataFrame({'files':files, 'AP':aps, 'F1':f1s, 'class_id':class_id,'PRECISION':PRECISION, \n",
    "                       'RECALL':RECALL, 'OVERLAPS':OVERLAPS})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if already run, has filenameImageIDindex file, starts here! \n",
    "# get mAP, precision, recall, F1 (per bb in an images)\n",
    "\n",
    "def generateMetrics():\n",
    "    df = pd.read_csv('/home/ubuntu/Mask_RCNN/data/video1FramesDataBatchTest/video1filenames.txt').rename(columns={'0':'files'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ready to anaylyze - approachA -- PUT true or detected files separately and count the number the files (1/0 per frame)\n",
    "\n",
    "def getNumberofInstance(path, modelUse, dataUse):\n",
    "    epoch1, epoch25, epoch50, epoch75, epoch100 = [], [], [], [], []\n",
    "    pre_pos_files = os.listdir(path)\n",
    "    for file in pre_pos_files:\n",
    "        if file.endswith('_0001.h5.jpg'):\n",
    "            epoch1.append(file)\n",
    "        elif file.endswith('_0025.h5.jpg'):\n",
    "            epoch25.append(file)\n",
    "        elif file.endswith('_0050.h5.jpg'):\n",
    "            epoch50.append(file)\n",
    "        elif file.endswith('_0075.h5.jpg'):\n",
    "            epoch75.append(file)\n",
    "        elif file.endswith('_0100.h5.jpg'):\n",
    "            epoch100.append(file)\n",
    "\n",
    "    df = pd.DataFrame({modelUse:[dataUse], \"epoch1\":len(epoch1), \"epoch25\":len(epoch25), \"epoch50\":len(epoch50), \n",
    "                       \"epoch75\":len(epoch75), \"epoch100\":[len(epoch100)]})\n",
    "    return(df)\n",
    "\n",
    "def TrueCount(path, modelUse, dataUse):\n",
    "    count = len(os.listdir(path))\n",
    "    df = pd.DataFrame({modelUse:[dataUse], \"TrueCount\":count})\n",
    "    return(df)\n",
    "\n",
    "def main():  #using files in true-folder \n",
    "    PredPos_val = getNumberofInstance('/home/ubuntu/Mask_RCNN/data/video1FramesDataBatchTest/outputMaskFrame', \n",
    "                                      \"set\",\"pred_pos_validation\")\n",
    "    PredTotal_val = getNumberofInstance('/home/ubuntu/Mask_RCNN/data/video1FramesDataBatchTest/outputAllFrame', \n",
    "                                      \"set\",\"pred_tol_validation\")\n",
    "    prediction = pd.concat([PredPos_val, PredTotal_val])\n",
    "    return prediction\n",
    "    \n",
    "def mainTrue():  #using files in true-folder \n",
    "    TruePos_val = TrueCount('/home/ubuntu/Mask_RCNN/data/video1Frames - True', \n",
    "                                      \"set\",\"true_pos_validation\")\n",
    "    gTrue = TruePos_val   \n",
    "    return gTrue\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    res = main()\n",
    "    resTrue = mainTrue()\n",
    "    Output = res.append(resTrue).T\n",
    "    Output.columns = Output.iloc[0]\n",
    "    Output = Output.drop([\"set\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready to analyze --- Approach 2 -- read xml annotation files vs. output object counts -- # objects per frame\n",
    "\n",
    "def getGroundTruthObjectCount(path):    \n",
    "    df_annotation = pd.read_csv(path)\n",
    "    df_annotation = df_annotation.drop(columns='Unnamed: 0')\n",
    "    df_annotation_count = df_annotation.pivot_table(index = 'imageID', columns='annot_objs', aggfunc= lambda x:len(x)).fillna(0)\n",
    "    #df_annotation_count = df_annotation_count.drop(columns='w')\n",
    "    return df_annotation_count\n",
    "\n",
    "\n",
    "def getPredObjectCount(path):\n",
    "    ObjCount_files = os.listdir(path)\n",
    "\n",
    "    a, b, c, d = [], [], [], []\n",
    "    for file in ObjCount_files:\n",
    "        if file.endswith('_0005.h5.txt'):\n",
    "            each_file = pd.read_csv(path + file)\n",
    "            each_file['ImageID'] = file.replace('_mask_rcnn_clown_cfg_0005.h5.txt','')\n",
    "            each_file['epoch'] = '0005'\n",
    "            a.append(each_file)\n",
    "            df_a = pd.concat(a)\n",
    "            df_a = df_a.drop(columns={'Unnamed: 0', 'image'})\n",
    "\n",
    "        elif file.endswith('_0015.h5.txt'):\n",
    "            each_file = pd.read_csv(path + file)\n",
    "            each_file['ImageID'] = file.replace('_mask_rcnn_clown_cfg_0015.h5.txt','')\n",
    "            each_file['epoch'] = '0015'\n",
    "            b.append(each_file)\n",
    "            df_b = pd.concat(b)\n",
    "            df_b = df_b.drop(columns={'Unnamed: 0', 'image'})\n",
    "\n",
    "\n",
    "        elif file.endswith('_0025.h5.txt'):\n",
    "            each_file = pd.read_csv(path + file)\n",
    "            each_file['ImageID'] = file.replace('_mask_rcnn_clown_cfg_0025.h5.txt','')\n",
    "            each_file['epoch'] = '0025'\n",
    "            c.append(each_file)\n",
    "            df_c = pd.concat(c)\n",
    "            df_c = df_c.drop(columns={'Unnamed: 0', 'image'})\n",
    "\n",
    "\n",
    "        elif file.endswith('_0038.h5.txt'):\n",
    "            each_file = pd.read_csv(path + file)\n",
    "            each_file['ImageID'] = file.replace('_mask_rcnn_clown_cfg_0038.h5.txt','')\n",
    "            each_file['epoch'] = '0038'\n",
    "            d.append(each_file)\n",
    "            df_d = pd.concat(d)\n",
    "            df_d = df_d.drop(columns={'Unnamed: 0', 'image'})\n",
    "\n",
    "    df_OutObj = pd.concat([df_a, df_b, df_c, df_d])\n",
    "    return df_OutObj\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    df_groundTruthTraining = getGroundTruthObjectCount('/home/ubuntu/Mask_RCNN/data/trainingAnnotation.txt')\n",
    "    df_groundTruthTraining.reset_index(inplace=True)\n",
    "    df_groundTruthTraining['files'] = df_groundTruthTraining['imageID']\n",
    "    df_groundTruthTraining = df_groundTruthTraining.drop(columns={'w', \"imageID\"})\n",
    "    df_groundTruthTraining['files'] = df_groundTruthTraining['files'].str.replace('.xml','')\n",
    "    df_groundTruthTraining.to_csv('/home/ubuntu/Mask_RCNN/data/reform_trainingAnnotation.txt')\n",
    "    \n",
    "    df_groundTruthVal = getGroundTruthObjectCount('/home/ubuntu/Mask_RCNN/data/testingAnnotation.txt')\n",
    "    df_groundTruthVal.reset_index(inplace=True)\n",
    "    df_groundTruthVal['files'] = df_groundTruthVal['imageID']\n",
    "    df_groundTruthVal = df_groundTruthVal.drop(columns={\"imageID\"})\n",
    "    df_groundTruthVal['files'] = df_groundTruthVal['files'].str.replace('.xml','')\n",
    "    df_groundTruthVal.to_csv('/home/ubuntu/Mask_RCNN/data/reform_testingAnnotation.txt')\n",
    "    \n",
    "    df_PredTraining = getPredObjectCount('/home/ubuntu/Mask_RCNN/data/TrainingResults/outputObjCount/')\n",
    "    df_PredTraining.to_csv('/home/ubuntu/Mask_RCNN/data/reform_TrainingoutputObjCount.txt')\n",
    "    \n",
    "    df_PredVal = getPredObjectCount('/home/ubuntu/Mask_RCNN/data/TestingResults/outputObjCount/')\n",
    "    df_PredVal.to_csv('/home/ubuntu/Mask_RCNN/data/reform_TestingoutputObjCount.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# togethers - groundTruth vs. prediction (trainig set)\n",
    "df_index_training = pd.read_csv('/home/ubuntu/Mask_RCNN/data/TrainfilevsImageID.txt')\n",
    "df_index_training['files'] = df_index_training['files'].str.replace(\"dataset.\",'')\n",
    "df_index_training = df_index.rename(columns= {'Unnamed: 0':'imageID'})\n",
    "df_index_training['imageID'] = df_index_training['imageID'].replace('.xml', \"\")\n",
    "\n",
    "truth = pd.merge(df_groundTruthTraining, df_index_training, on = ['files'], how ='outer')\n",
    "truth = truth.rename(columns={'clown':'true_clown', 'color':'true_color', 'nface':'true_nface' })\n",
    "\n",
    "df_PredTraining = df_PredTraining.rename(columns = {'ImageID':'imageID'})\n",
    "\n",
    "all_file = []\n",
    "for e in df_PredTraining.epoch.unique():\n",
    "    dfsub = df_PredTraining[(df_PredTraining.epoch == e)]\n",
    "    dfsub['imageID'] = dfsub['imageID'].astype(int)\n",
    "    submerge = pd.merge(truth, dfsub, on=['imageID'], how='outer')\n",
    "    all_file.append(submerge)\n",
    "    \n",
    "df1 = all_file[0]\n",
    "df2 = all_file[1]\n",
    "df3 = all_file[2]\n",
    "df4 = all_file[3]\n",
    "training_truth_pred_objCount = pd.concat([df1, df2, df3, df4])\n",
    "training_truth_pred_objCount.to_csv('/home/ubuntu/Mask_RCNN/data/Training_truth_pred_objCount.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# togethers - groundTruth vs. prediction (validation set)\n",
    "df_index_testing = pd.read_csv('/home/ubuntu/Mask_RCNN/data/TestfilevsImageID.txt')\n",
    "df_index_testing['files'] = df_index_testing['files'].str.replace(\"dataset.\",'')\n",
    "df_index_testing = df_index_testing.rename(columns= {'Unnamed: 0':'imageID'})\n",
    "df_index_testing['imageID'] = df_index_testing['imageID'].replace('.xml', \"\")\n",
    "\n",
    "\n",
    "truth_val = pd.merge(df_groundTruthVal, df_index_testing, on = ['files'], how ='outer')\n",
    "truth_val = truth_val.rename(columns={'clown':'val_clown', 'color':'val_color', 'nface':'val_nface' })\n",
    "\n",
    "df_PredVal = df_PredVal.rename(columns = {'ImageID':'imageID'})\n",
    "\n",
    "all_file_val = []\n",
    "for e in df_PredVal.epoch.unique():\n",
    "    dfsub_val = df_PredVal[(df_PredVal.epoch == e)]\n",
    "    dfsub_val['imageID'] = dfsub_val['imageID'].astype(int)\n",
    "    submerge_val = pd.merge(truth_val, dfsub_val, on=['imageID'], how='outer')\n",
    "    all_file_val.append(submerge_val)\n",
    "    \n",
    "df1_val = all_file_val[0]\n",
    "df2_val = all_file_val[1]\n",
    "df3_val = all_file_val[2]\n",
    "df4_val = all_file_val[3]\n",
    "testing_truth_pred_objCount = pd.concat([df1_val, df2_val, df3_val, df4_val])\n",
    "testing_truth_pred_objCount.to_csv('/home/ubuntu/Mask_RCNN/data/Testing_truth_pred_objCount.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Starts - Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrics based on # of images (each image evaluation)\n",
    "\n",
    "def TruefilesNumber(pathTrueImage, DataUse):\n",
    "    \n",
    "    fileassign = generateMetrics()\n",
    "    fileassign['imageID'] = fileassign.index\n",
    "    IndexFiles = fileassign[['imageID', 'files']]\n",
    "    IndexFiles['files'] = IndexFiles['files'].str.replace('dataset.',\"\")\n",
    "\n",
    "    TrueFileConvert = []\n",
    "    TrueFiles = os.listdir(pathTrueImage)\n",
    "    for f in TrueFiles:\n",
    "        TrueFileConvert.append(f.split(\".\")[0])\n",
    "    Truefile = pd.DataFrame({'files': TrueFileConvert})\n",
    "\n",
    "    f = pd.merge(IndexFiles, Truefile, on=\"files\", how='inner')\n",
    "    f[DataUse] = 'TruePositive'\n",
    "    \n",
    "    return f\n",
    "\n",
    "def mainVal():\n",
    "    val = TruefilesNumber('/home/ubuntu/Mask_RCNN/data/video1Frames - True',\n",
    "                    'validation')\n",
    "    return val\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TrueVal = mainVal()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runningFiles(pathtooutput):\n",
    "    ID, epoch = [], []\n",
    "    files = os.listdir(pathtooutput)\n",
    "    for file in files:\n",
    "        ID.append(file.split('_')[0])\n",
    "        epoch.append(file.split('_')[5].split('.')[0])\n",
    "    inFile = pd.DataFrame({\"imageID\": ID, \"Epoch\": epoch})\n",
    "    return inFile\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    PredValAllfiles = runningFiles('/home/ubuntu/Mask_RCNN/data/video1FramesDataBatchTest/outputAllFrame')\n",
    "    PredValPosfiles = runningFiles('/home/ubuntu/Mask_RCNN/data/video1FramesDataBatchTest/outputMaskFrame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "PredValPosfiles['validation'] = 'PredPositive'\n",
    "vali = pd.merge(PredValAllfiles, PredValPosfiles, on=['imageID', 'Epoch'], how='outer')  \n",
    "vali = vali.fillna('PredNegative')\n",
    "listTrueVal = [str(i) for i in list(TrueVal['imageID'])]\n",
    "PreVal = vali[vali['imageID'].isin(listTrueVal)]\n",
    "PreVal['validation_Truth'] = 'TruePostive'\n",
    "PreValf = vali[~vali['imageID'].isin(listTrueVal)]\n",
    "PreValf['validation_Truth'] = 'TrueNegative'\n",
    "ValidationData = pd.concat([PreVal, PreValf])\n",
    "\n",
    "ep, pp, pn, np, nn = [], [], [],[], []\n",
    "for e in ValidationData['Epoch'].unique():   \n",
    "    ValidationData1 = ValidationData.groupby(['Epoch']).get_group(e)\n",
    "    pp.append(len(ValidationData1[(ValidationData1['validation']=='PredPositive') \n",
    "                                      &(ValidationData1['validation_Truth']=='TruePostive')]))\n",
    "    pn.append(len(ValidationData1[(ValidationData1['validation']=='PredPositive') \n",
    "                                      &(ValidationData1['validation_Truth']=='TrueNegative')]))\n",
    "    np.append(len(ValidationData1[(ValidationData1['validation']=='PredNegative') \n",
    "                                      &(ValidationData1['validation_Truth']=='TruePostive')]))\n",
    "    nn.append(len(ValidationData1[(ValidationData1['validation']=='PredNegative') \n",
    "                                      &(ValidationData1['validation_Truth']=='TrueNegative')]))\n",
    "    ep.append(e)\n",
    "    \n",
    "    validationMatrix = pd.DataFrame({'Epoch':ep, 'PrePos_TruePos': pp, 'PrePos_TrueNeg': pn, 'PreNeg_TruePos': np,\n",
    "                                    'PreNeg_TrueNeg': nn})\n",
    "    \n",
    "validationMatrix.sort_values(by=['Epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the results\n",
    "Output.to_csv('/home/ubuntu/Mask_RCNN/data/outputMetrics/totalNumberImages.txt')\n",
    "validationMatrix.to_csv('/home/ubuntu/Mask_RCNN/data/outputMetrics/validationMatrix.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Starts - Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNNPPTNNPforEpoch(data_file):\n",
    "\n",
    "    NN = data_file[(data_file.true_clown == 0.0) & (\n",
    "    data_file['#clown'] == 0.0)]\n",
    "\n",
    "    PP = data_file[(data_file.true_clown != 0.0) & (\n",
    "    data_file['#clown'] != 0.0)] \n",
    "\n",
    "    NP = data_file[(data_file.true_clown == 0.0) & (\n",
    "    data_file['#clown'] != 0.0)] \n",
    "\n",
    "    PN = data_file[(data_file.true_clown != 0.0) & (\n",
    "    data_file['#clown'] == 0.0)] \n",
    "\n",
    "    nn = NN.pivot_table(index='epoch', aggfunc = lambda x:len(x))\n",
    "    nn.reset_index(inplace=True)\n",
    "    nn['NN'] = nn['#clown'] #use any\n",
    "    nn = nn.drop(columns={'#clown', '#nface', 'files', 'imageID', 'true_clown','true_color', 'true_nface'})\n",
    "\n",
    "    pp = PP.pivot_table(index='epoch', aggfunc = lambda x:len(x))\n",
    "    pp.reset_index(inplace=True)\n",
    "    pp['PP'] = pp['#clown'] #use any\n",
    "    pp = pp.drop(columns={'#clown', '#nface', 'files', 'imageID', 'true_clown','true_color', 'true_nface'})\n",
    "\n",
    "    np = NP.pivot_table(index='epoch', aggfunc = lambda x:len(x))\n",
    "    np.reset_index(inplace=True)\n",
    "    np['NP'] = np['#clown'] #use any\n",
    "    np = np.drop(columns={'#clown', '#nface', 'files', 'imageID', 'true_clown','true_color', 'true_nface'})\n",
    "\n",
    "    pn = PN.pivot_table(index='epoch', aggfunc = lambda x:len(x))\n",
    "    pn.reset_index(inplace=True)\n",
    "    pn['PN'] = pn['#clown'] #use any\n",
    "    pn = pn.drop(columns={'#clown', '#nface', 'files', 'imageID', 'true_clown','true_color', 'true_nface'})\n",
    "\n",
    "    df_all = pd.concat([nn, pp, np, pn], axis = 1).drop_duplicates()\n",
    "    df_all = df_all.loc[:,~df_all.columns.duplicated()]\n",
    "    \n",
    "    return df_all\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "# cut out google images \n",
    "    training_truth_pred_objCount = training_truth_pred_objCount.sort_values(by=['files']).iloc[0:2464]\n",
    "    df_training_PPNNPNNP_tabel = generateNNPPTNNPforEpoch(training_truth_pred_objCount)\n",
    "    df_training_PPNNPNNP_tabel.to_csv('/home/ubuntu/Mask_RCNN/data/training_forConfusionTablePlot.txt')\n",
    "    \n",
    "# fix names    \n",
    "    testing_truth_pred_objCount = testing_truth_pred_objCount.rename(columns={'val_clown':'true_clown',\n",
    "                                           'val_color':'true_color',\n",
    "                                           'val_nface':'true_nface'})\n",
    "    df_testing_PPNNPNNP_tabel = generateNNPPTNNPforEpoch(testing_truth_pred_objCount)\n",
    "    df_testing_PPNNPNNP_tabel.to_csv('/home/ubuntu/Mask_RCNN/data/testing_forConfusionTablePlot.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>NN</th>\n",
       "      <th>PP</th>\n",
       "      <th>NP</th>\n",
       "      <th>PN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005</td>\n",
       "      <td>51</td>\n",
       "      <td>343</td>\n",
       "      <td>161</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0015</td>\n",
       "      <td>47</td>\n",
       "      <td>362</td>\n",
       "      <td>165</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0025</td>\n",
       "      <td>55</td>\n",
       "      <td>339</td>\n",
       "      <td>157</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0038</td>\n",
       "      <td>102</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch   NN   PP   NP  PN\n",
       "0  0005   51  343  161  61\n",
       "1  0015   47  362  165  42\n",
       "2  0025   55  339  157  65\n",
       "3  0038  102  324  110  80"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_PPNNPNNP_tabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>NN</th>\n",
       "      <th>PP</th>\n",
       "      <th>NP</th>\n",
       "      <th>PN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005</td>\n",
       "      <td>17</td>\n",
       "      <td>105</td>\n",
       "      <td>59</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0015</td>\n",
       "      <td>10</td>\n",
       "      <td>108</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0025</td>\n",
       "      <td>14</td>\n",
       "      <td>115</td>\n",
       "      <td>62</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0038</td>\n",
       "      <td>39</td>\n",
       "      <td>102</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch  NN   PP  NP  PN\n",
       "0  0005  17  105  59  26\n",
       "1  0015  10  108  66  23\n",
       "2  0025  14  115  62  16\n",
       "3  0038  39  102  37  29"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing_PPNNPNNP_tabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
